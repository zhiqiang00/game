{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_linear_logit' from 'deepctr_torch.models.basemodel' (/Users/wzq/anaconda3/envs/torch/lib/python3.8/site-packages/deepctr_torch/models/basemodel.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Concatenate\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepctr_torch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasemodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_input_features, get_linear_logit, input_from_feature_columns\n\u001b[1;32m     16\u001b[0m pd\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mmax_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m \u001b[38;5;66;03m#Notebook 的一个cell的显示行数\u001b[39;00m\n\u001b[1;32m     17\u001b[0m pd\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mmax_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m\u001b[38;5;66;03m#Notebook 的一个cell的显示列数\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_linear_logit' from 'deepctr_torch.models.basemodel' (/Users/wzq/anaconda3/envs/torch/lib/python3.8/site-packages/deepctr_torch/models/basemodel.py)"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr_torch.models import *\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Dense, Concatenate\n",
    "from deepctr_torch.models.basemodel import build_input_features, get_linear_logit, input_from_feature_columns\n",
    "\n",
    "\n",
    "pd.options.display.max_rows=10000 #Notebook 的一个cell的显示行数\n",
    "pd.options.display.max_columns=10000#Notebook 的一个cell的显示列数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/wzq/Desktop/coding/DeepCTR-Torch/examples/criteo_sample.txt')\n",
    "\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0, )\n",
    "target = ['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "# 这里其实是将字符串等映射为数字，这样方便后续进行look up embedding\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat(name='C1', vocabulary_size=27, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C1', group_name='default_group'),\n",
       " SparseFeat(name='C2', vocabulary_size=92, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C2', group_name='default_group'),\n",
       " SparseFeat(name='C3', vocabulary_size=172, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C3', group_name='default_group'),\n",
       " SparseFeat(name='C4', vocabulary_size=157, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C4', group_name='default_group'),\n",
       " SparseFeat(name='C5', vocabulary_size=12, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C5', group_name='default_group'),\n",
       " SparseFeat(name='C6', vocabulary_size=7, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C6', group_name='default_group'),\n",
       " SparseFeat(name='C7', vocabulary_size=183, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C7', group_name='default_group'),\n",
       " SparseFeat(name='C8', vocabulary_size=19, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C8', group_name='default_group'),\n",
       " SparseFeat(name='C9', vocabulary_size=2, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C9', group_name='default_group'),\n",
       " SparseFeat(name='C10', vocabulary_size=142, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C10', group_name='default_group'),\n",
       " SparseFeat(name='C11', vocabulary_size=173, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C11', group_name='default_group'),\n",
       " SparseFeat(name='C12', vocabulary_size=170, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C12', group_name='default_group'),\n",
       " SparseFeat(name='C13', vocabulary_size=166, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C13', group_name='default_group'),\n",
       " SparseFeat(name='C14', vocabulary_size=14, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C14', group_name='default_group'),\n",
       " SparseFeat(name='C15', vocabulary_size=170, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C15', group_name='default_group'),\n",
       " SparseFeat(name='C16', vocabulary_size=168, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C16', group_name='default_group'),\n",
       " SparseFeat(name='C17', vocabulary_size=9, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C17', group_name='default_group'),\n",
       " SparseFeat(name='C18', vocabulary_size=127, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C18', group_name='default_group'),\n",
       " SparseFeat(name='C19', vocabulary_size=44, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C19', group_name='default_group'),\n",
       " SparseFeat(name='C20', vocabulary_size=4, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C20', group_name='default_group'),\n",
       " SparseFeat(name='C21', vocabulary_size=169, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C21', group_name='default_group'),\n",
       " SparseFeat(name='C22', vocabulary_size=6, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C22', group_name='default_group'),\n",
       " SparseFeat(name='C23', vocabulary_size=10, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C23', group_name='default_group'),\n",
       " SparseFeat(name='C24', vocabulary_size=125, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C24', group_name='default_group'),\n",
       " SparseFeat(name='C25', vocabulary_size=20, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C25', group_name='default_group'),\n",
       " SparseFeat(name='C26', vocabulary_size=90, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C26', group_name='default_group'),\n",
       " DenseFeat(name='I1', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I2', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I3', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I4', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I5', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I6', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I7', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I8', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I9', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I10', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I11', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I12', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I13', dimension=1, dtype='float32')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.count #unique features for each sparse field,and record dense feature field name\n",
    "# 生成一个了元素为SparseFeat类别的list，每个元素namedtuple：类似于一个轻量级的类，它允许创建具名字段的元组，可以像类一样使用。\n",
    "# with signature：指的是创建这个 namedtuple 时的字段顺序和名称，也就是在实例化时需要按顺序传入这些字段的值。\n",
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].max() + 1, embedding_dim=4)\n",
    "                            for feat in sparse_features] + [DenseFeat(feat, 1, )\n",
    "                                                            for feat in dense_features]\n",
    "fixlen_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.092362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.059628</td>\n",
       "      <td>0.117284</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.154739</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.077873</td>\n",
       "      <td>0.019934</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.505803</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0.033185</td>\n",
       "      <td>0.094967</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.028046</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.036945</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.067426</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.035783</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.040142</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.273029</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.206963</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>17</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.014507</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063123</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.072650</td>\n",
       "      <td>0.265781</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.491296</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label        I1        I2        I3        I4        I5        I6  \\\n",
       "0        0  0.000000  0.001332  0.092362  0.000000  0.034825  0.000000   \n",
       "1        0  0.000000  0.000000  0.006750  0.402299  0.059628  0.117284   \n",
       "2        0  0.000000  0.000333  0.000710  0.137931  0.003968  0.077873   \n",
       "3        0  0.000000  0.004664  0.000355  0.045977  0.033185  0.094967   \n",
       "4        0  0.000000  0.000333  0.036945  0.310345  0.003922  0.067426   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "195      0  0.000000  0.000333  0.040142  0.034483  0.005984  0.273029   \n",
       "196      1  0.000000  0.000666  0.000355  0.011494  0.003168  0.005698   \n",
       "197      1  0.027027  0.000333  0.002131  0.034483  0.000000  0.000000   \n",
       "198      0  0.000000  0.007662  0.002131  0.252874  0.000400  0.072650   \n",
       "199      0  0.027027  0.000000  0.000000  0.000000  0.000272  0.000000   \n",
       "\n",
       "           I7        I8        I9  ...  C17  C18  C19  C20  C21  C22  C23  \\\n",
       "0    0.000000  0.673469  0.000000  ...    8   66    0    0    3    0    1   \n",
       "1    0.003322  0.714286  0.154739  ...    7   52    0    0   47    0    7   \n",
       "2    0.019934  0.714286  0.505803  ...    8   49    0    0   25    0    6   \n",
       "3    0.016611  0.081633  0.028046  ...    8   37    0    0  156    0    0   \n",
       "4    0.013289  0.653061  0.035783  ...    8   14    5    3    9    0    0   \n",
       "..        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "195  0.006645  0.061224  0.206963  ...    0   74    5    1   30    5    0   \n",
       "196  0.003322  0.244898  0.014507  ...    1   25    0    0  138    0    0   \n",
       "197  0.063123  0.061224  0.002901  ...    4   40   17    2   41    0    0   \n",
       "198  0.265781  0.367347  0.491296  ...    4    7   18    1  123    0    0   \n",
       "199  0.003322  0.000000  0.000000  ...    7   72    0    0    0    0    0   \n",
       "\n",
       "     C24  C25  C26  \n",
       "0     96    0    0  \n",
       "1    112    0    0  \n",
       "2     53    0    0  \n",
       "3     32    0    0  \n",
       "4      5    1   47  \n",
       "..   ...  ...  ...  \n",
       "195  118   17   48  \n",
       "196   68    0    0  \n",
       "197   12   16   11  \n",
       "198   10   16   49  \n",
       "199    0    0    0  \n",
       "\n",
       "[200 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat(name='C1', vocabulary_size=27, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C1', group_name='default_group'),\n",
       " SparseFeat(name='C2', vocabulary_size=92, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C2', group_name='default_group'),\n",
       " SparseFeat(name='C3', vocabulary_size=172, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C3', group_name='default_group'),\n",
       " SparseFeat(name='C4', vocabulary_size=157, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C4', group_name='default_group'),\n",
       " SparseFeat(name='C5', vocabulary_size=12, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C5', group_name='default_group'),\n",
       " SparseFeat(name='C6', vocabulary_size=7, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C6', group_name='default_group'),\n",
       " SparseFeat(name='C7', vocabulary_size=183, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C7', group_name='default_group'),\n",
       " SparseFeat(name='C8', vocabulary_size=19, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C8', group_name='default_group'),\n",
       " SparseFeat(name='C9', vocabulary_size=2, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C9', group_name='default_group'),\n",
       " SparseFeat(name='C10', vocabulary_size=142, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C10', group_name='default_group'),\n",
       " SparseFeat(name='C11', vocabulary_size=173, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C11', group_name='default_group'),\n",
       " SparseFeat(name='C12', vocabulary_size=170, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C12', group_name='default_group'),\n",
       " SparseFeat(name='C13', vocabulary_size=166, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C13', group_name='default_group'),\n",
       " SparseFeat(name='C14', vocabulary_size=14, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C14', group_name='default_group'),\n",
       " SparseFeat(name='C15', vocabulary_size=170, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C15', group_name='default_group'),\n",
       " SparseFeat(name='C16', vocabulary_size=168, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C16', group_name='default_group'),\n",
       " SparseFeat(name='C17', vocabulary_size=9, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C17', group_name='default_group'),\n",
       " SparseFeat(name='C18', vocabulary_size=127, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C18', group_name='default_group'),\n",
       " SparseFeat(name='C19', vocabulary_size=44, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C19', group_name='default_group'),\n",
       " SparseFeat(name='C20', vocabulary_size=4, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C20', group_name='default_group'),\n",
       " SparseFeat(name='C21', vocabulary_size=169, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C21', group_name='default_group'),\n",
       " SparseFeat(name='C22', vocabulary_size=6, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C22', group_name='default_group'),\n",
       " SparseFeat(name='C23', vocabulary_size=10, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C23', group_name='default_group'),\n",
       " SparseFeat(name='C24', vocabulary_size=125, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C24', group_name='default_group'),\n",
       " SparseFeat(name='C25', vocabulary_size=20, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C25', group_name='default_group'),\n",
       " SparseFeat(name='C26', vocabulary_size=90, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C26', group_name='default_group'),\n",
       " DenseFeat(name='I1', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I2', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I3', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I4', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I5', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I6', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I7', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I8', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I9', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I10', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I11', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I12', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I13', dimension=1, dtype='float32'),\n",
       " SparseFeat(name='C1', vocabulary_size=27, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C1', group_name='default_group'),\n",
       " SparseFeat(name='C2', vocabulary_size=92, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C2', group_name='default_group'),\n",
       " SparseFeat(name='C3', vocabulary_size=172, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C3', group_name='default_group'),\n",
       " SparseFeat(name='C4', vocabulary_size=157, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C4', group_name='default_group'),\n",
       " SparseFeat(name='C5', vocabulary_size=12, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C5', group_name='default_group'),\n",
       " SparseFeat(name='C6', vocabulary_size=7, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C6', group_name='default_group'),\n",
       " SparseFeat(name='C7', vocabulary_size=183, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C7', group_name='default_group'),\n",
       " SparseFeat(name='C8', vocabulary_size=19, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C8', group_name='default_group'),\n",
       " SparseFeat(name='C9', vocabulary_size=2, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C9', group_name='default_group'),\n",
       " SparseFeat(name='C10', vocabulary_size=142, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C10', group_name='default_group'),\n",
       " SparseFeat(name='C11', vocabulary_size=173, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C11', group_name='default_group'),\n",
       " SparseFeat(name='C12', vocabulary_size=170, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C12', group_name='default_group'),\n",
       " SparseFeat(name='C13', vocabulary_size=166, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C13', group_name='default_group'),\n",
       " SparseFeat(name='C14', vocabulary_size=14, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C14', group_name='default_group'),\n",
       " SparseFeat(name='C15', vocabulary_size=170, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C15', group_name='default_group'),\n",
       " SparseFeat(name='C16', vocabulary_size=168, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C16', group_name='default_group'),\n",
       " SparseFeat(name='C17', vocabulary_size=9, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C17', group_name='default_group'),\n",
       " SparseFeat(name='C18', vocabulary_size=127, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C18', group_name='default_group'),\n",
       " SparseFeat(name='C19', vocabulary_size=44, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C19', group_name='default_group'),\n",
       " SparseFeat(name='C20', vocabulary_size=4, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C20', group_name='default_group'),\n",
       " SparseFeat(name='C21', vocabulary_size=169, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C21', group_name='default_group'),\n",
       " SparseFeat(name='C22', vocabulary_size=6, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C22', group_name='default_group'),\n",
       " SparseFeat(name='C23', vocabulary_size=10, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C23', group_name='default_group'),\n",
       " SparseFeat(name='C24', vocabulary_size=125, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C24', group_name='default_group'),\n",
       " SparseFeat(name='C25', vocabulary_size=20, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C25', group_name='default_group'),\n",
       " SparseFeat(name='C26', vocabulary_size=90, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C26', group_name='default_group'),\n",
       " DenseFeat(name='I1', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I2', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I3', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I4', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I5', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I6', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I7', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I8', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I9', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I10', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I11', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I12', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I13', dimension=1, dtype='float32')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "linear_feature_columns + dnn_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_input_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbuild_input_features\u001b[49m(dnn_feature_columns)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_input_features' is not defined"
     ]
    }
   ],
   "source": [
    "build_input_features(dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76     146\n",
      "34      72\n",
      "1       98\n",
      "40      34\n",
      "151    160\n",
      "111    149\n",
      "18     105\n",
      "8      141\n",
      "60      13\n",
      "93      67\n",
      "107    146\n",
      "109    144\n",
      "26      52\n",
      "31     103\n",
      "162    101\n",
      "97      80\n",
      "137     64\n",
      "53      33\n",
      "159     57\n",
      "189      0\n",
      "49      19\n",
      "144    132\n",
      "110     17\n",
      "123     82\n",
      "72     135\n",
      "4       59\n",
      "166     30\n",
      "124     16\n",
      "105     92\n",
      "25      69\n",
      "183    116\n",
      "141     65\n",
      "135    143\n",
      "103     99\n",
      "43     114\n",
      "51      71\n",
      "81      49\n",
      "167    114\n",
      "86       4\n",
      "78     164\n",
      "116    125\n",
      "7       31\n",
      "17     166\n",
      "85      77\n",
      "138    171\n",
      "45      21\n",
      "54      45\n",
      "178     82\n",
      "61      36\n",
      "56      90\n",
      "155    119\n",
      "113     85\n",
      "84       0\n",
      "194     20\n",
      "74      87\n",
      "146     79\n",
      "187    159\n",
      "153      8\n",
      "100    150\n",
      "168    161\n",
      "106    170\n",
      "170    123\n",
      "94      28\n",
      "47     126\n",
      "44      75\n",
      "165    146\n",
      "77       0\n",
      "36     130\n",
      "3        7\n",
      "180    148\n",
      "197    153\n",
      "15      60\n",
      "132     74\n",
      "32     155\n",
      "12     122\n",
      "0       96\n",
      "59       1\n",
      "193     86\n",
      "50     145\n",
      "39      93\n",
      "19      35\n",
      "176    136\n",
      "58     165\n",
      "128    146\n",
      "16     121\n",
      "37      56\n",
      "75       0\n",
      "122     81\n",
      "158    133\n",
      "171     45\n",
      "127    107\n",
      "63     120\n",
      "24     100\n",
      "13       0\n",
      "126     70\n",
      "46     102\n",
      "22     154\n",
      "30     151\n",
      "172     54\n",
      "64      50\n",
      "147     11\n",
      "10     137\n",
      "99     139\n",
      "174     22\n",
      "133    103\n",
      "142    162\n",
      "14      47\n",
      "80      29\n",
      "33      10\n",
      "66      63\n",
      "65      18\n",
      "121    111\n",
      "112    127\n",
      "82      31\n",
      "83     152\n",
      "185     32\n",
      "52      46\n",
      "173    115\n",
      "182     15\n",
      "20     113\n",
      "192      0\n",
      "98      83\n",
      "134      5\n",
      "149     38\n",
      "150    118\n",
      "6      168\n",
      "90      55\n",
      "29      40\n",
      "21      73\n",
      "62     158\n",
      "73      58\n",
      "190     62\n",
      "79     109\n",
      "129    159\n",
      "38      51\n",
      "198     84\n",
      "148      2\n",
      "156     24\n",
      "188     37\n",
      "69      42\n",
      "102    169\n",
      "114      9\n",
      "55     131\n",
      "139     94\n",
      "179    156\n",
      "9      157\n",
      "152    117\n",
      "160    142\n",
      "48      89\n",
      "157     82\n",
      "184    124\n",
      "71       7\n",
      "131     76\n",
      "125     41\n",
      "91      68\n",
      "195     66\n",
      "118      0\n",
      "67      78\n",
      "136      0\n",
      "96      97\n",
      "Name: C3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3.generate input data for model\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=2020)\n",
    "train_model_input = {name: train[name] for name in feature_names}\n",
    "test_model_input = {name: test[name] for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 128 samples, validate on 32 samples, 1 steps per epoch\n",
      "Epoch 1/10\n",
      "0s - loss:  0.6897 - binary_crossentropy:  0.6897 - val_binary_crossentropy:  0.6806\n",
      "Epoch 2/10\n",
      "0s - loss:  0.6760 - binary_crossentropy:  0.6760 - val_binary_crossentropy:  0.6722\n",
      "Epoch 3/10\n",
      "0s - loss:  0.6623 - binary_crossentropy:  0.6623 - val_binary_crossentropy:  0.6640\n",
      "Epoch 4/10\n",
      "0s - loss:  0.6488 - binary_crossentropy:  0.6488 - val_binary_crossentropy:  0.6559\n",
      "Epoch 5/10\n",
      "0s - loss:  0.6356 - binary_crossentropy:  0.6356 - val_binary_crossentropy:  0.6482\n",
      "Epoch 6/10\n",
      "0s - loss:  0.6227 - binary_crossentropy:  0.6227 - val_binary_crossentropy:  0.6408\n",
      "Epoch 7/10\n",
      "0s - loss:  0.6099 - binary_crossentropy:  0.6099 - val_binary_crossentropy:  0.6335\n",
      "Epoch 8/10\n",
      "0s - loss:  0.5974 - binary_crossentropy:  0.5974 - val_binary_crossentropy:  0.6267\n",
      "Epoch 9/10\n",
      "0s - loss:  0.5851 - binary_crossentropy:  0.5851 - val_binary_crossentropy:  0.6201\n",
      "Epoch 10/10\n",
      "0s - loss:  0.5729 - binary_crossentropy:  0.5729 - val_binary_crossentropy:  0.6136\n",
      "test LogLoss 0.6072\n",
      "test AUC 0.5161\n"
     ]
    }
   ],
   "source": [
    "# 4.Define Model,train,predict and evaluate\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary')\n",
    "model.compile(\"adam\", \"binary_crossentropy\",\n",
    "                  metrics=['binary_crossentropy'], )\n",
    "\n",
    "history = model.fit(train_model_input, train[target].values,\n",
    "                    batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "\n",
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
