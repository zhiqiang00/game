{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from lightgbm import log_evaluation, early_stopping\n",
    "\n",
    "\n",
    "# jupyter配置\n",
    "pd.options.display.max_rows=None #Notebook 的一个cell的显示行数\n",
    "pd.options.display.max_columns=None#Notebook 的一个cell的显示列数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练数据\n",
    "train_data_x = np.load('./train_data/train_x.npy')\n",
    "train_data_y = np.load('./train_data/train_y.npy')\n",
    "# 读取测试数据\n",
    "test_x_A = np.load(\"./test_data/test_x_A.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里先做做一个简易版，先把两个观测指标片接到一起，即每个样本特征是180+180长度\n",
    "train_data_x_reshape = train_data_x.reshape(train_data_x.shape[0], -1)\n",
    "test_x_A_reshape = test_x_A.reshape(test_x_A.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape (26284, 360)\n",
      "test_x.shape (11265, 360)\n",
      "train_y.shape (26284,)\n",
      "test_y.shape (11265,)\n",
      "test_x_A.shape (1155, 2, 180)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data_x_reshape, train_data_y, test_size=0.3)\n",
    "print(\"train_x.shape\", X_train.shape)\n",
    "print(\"test_x.shape\", X_test.shape)\n",
    "print(\"train_y.shape\", y_train.shape)\n",
    "print(\"test_y.shape\", y_test.shape)\n",
    "print(\"test_x_A.shape\", test_x_A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. RandomForestClassifier expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[201], line 15\u001b[0m\n\u001b[1;32m      2\u001b[0m rfc \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 交叉验证\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# rfc_s = cross_val_score(rfc,train_x, train_y,cv=10)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# plt.plot(range(1,11),rfc_s,label = \"RandomForest\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 直接利用全量数据训练\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mrfc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m res \u001b[38;5;241m=\u001b[39m rfc\u001b[38;5;241m.\u001b[39mpredict(test_x_A)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m预测结果shape：\u001b[39m\u001b[38;5;124m\"\u001b[39m,res\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/sklearn/base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/sklearn/utils/validation.py:953\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    950\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    951\u001b[0m     )\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    959\u001b[0m     _assert_all_finite(\n\u001b[1;32m    960\u001b[0m         array,\n\u001b[1;32m    961\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    962\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    963\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    964\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. RandomForestClassifier expected <= 2."
     ]
    }
   ],
   "source": [
    "# 随机深林模型训练\n",
    "rfc = RandomForestClassifier(n_estimators=25)\n",
    "\n",
    "# 交叉验证\n",
    "# rfc_s = cross_val_score(rfc,train_x, train_y,cv=10)\n",
    "# plt.plot(range(1,11),rfc_s,label = \"RandomForest\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# rfc.fit(train_x, train_y)\n",
    "# res = rfc.predict(test_x)\n",
    "\n",
    "# 直接利用全量数据训练\n",
    "rfc.fit(train_data_x, train_data_y)\n",
    "res = rfc.predict(test_x_A)\n",
    "\n",
    "print(\"预测结果shape：\",res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.9979582778517532\n"
     ]
    }
   ],
   "source": [
    "# 预测结果验证\n",
    "# 0.7数据训练 0.8458055925432756\n",
    "score_r = rfc.score(X_test, y_test)\n",
    "print(\"Random Forest:\",score_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.00422\ttest-mlogloss:1.01076\n",
      "[1]\ttrain-mlogloss:0.92587\ttest-mlogloss:0.93840\n",
      "[2]\ttrain-mlogloss:0.85822\ttest-mlogloss:0.87630\n",
      "[3]\ttrain-mlogloss:0.80011\ttest-mlogloss:0.82335\n",
      "[4]\ttrain-mlogloss:0.74910\ttest-mlogloss:0.77787\n",
      "[5]\ttrain-mlogloss:0.70358\ttest-mlogloss:0.73813\n",
      "[6]\ttrain-mlogloss:0.66461\ttest-mlogloss:0.70426\n",
      "[7]\ttrain-mlogloss:0.62844\ttest-mlogloss:0.67358\n",
      "[8]\ttrain-mlogloss:0.59757\ttest-mlogloss:0.64778\n",
      "[9]\ttrain-mlogloss:0.56907\ttest-mlogloss:0.62371\n",
      "[10]\ttrain-mlogloss:0.54308\ttest-mlogloss:0.60285\n",
      "[11]\ttrain-mlogloss:0.51988\ttest-mlogloss:0.58440\n",
      "[12]\ttrain-mlogloss:0.50094\ttest-mlogloss:0.56940\n",
      "[13]\ttrain-mlogloss:0.48349\ttest-mlogloss:0.55570\n",
      "[14]\ttrain-mlogloss:0.46701\ttest-mlogloss:0.54310\n",
      "[15]\ttrain-mlogloss:0.45238\ttest-mlogloss:0.53219\n",
      "[16]\ttrain-mlogloss:0.43905\ttest-mlogloss:0.52263\n",
      "[17]\ttrain-mlogloss:0.42630\ttest-mlogloss:0.51405\n",
      "[18]\ttrain-mlogloss:0.41389\ttest-mlogloss:0.50567\n",
      "[19]\ttrain-mlogloss:0.40119\ttest-mlogloss:0.49710\n",
      "[20]\ttrain-mlogloss:0.39019\ttest-mlogloss:0.48997\n",
      "[21]\ttrain-mlogloss:0.37990\ttest-mlogloss:0.48327\n",
      "[22]\ttrain-mlogloss:0.37040\ttest-mlogloss:0.47744\n",
      "[23]\ttrain-mlogloss:0.36191\ttest-mlogloss:0.47240\n",
      "[24]\ttrain-mlogloss:0.35331\ttest-mlogloss:0.46709\n",
      "[25]\ttrain-mlogloss:0.34517\ttest-mlogloss:0.46246\n",
      "[26]\ttrain-mlogloss:0.33723\ttest-mlogloss:0.45806\n",
      "[27]\ttrain-mlogloss:0.33026\ttest-mlogloss:0.45442\n",
      "[28]\ttrain-mlogloss:0.32368\ttest-mlogloss:0.45117\n",
      "[29]\ttrain-mlogloss:0.31715\ttest-mlogloss:0.44763\n",
      "[30]\ttrain-mlogloss:0.31129\ttest-mlogloss:0.44466\n",
      "[31]\ttrain-mlogloss:0.30544\ttest-mlogloss:0.44173\n",
      "[32]\ttrain-mlogloss:0.30038\ttest-mlogloss:0.43917\n",
      "[33]\ttrain-mlogloss:0.29559\ttest-mlogloss:0.43697\n",
      "[34]\ttrain-mlogloss:0.29077\ttest-mlogloss:0.43497\n",
      "[35]\ttrain-mlogloss:0.28620\ttest-mlogloss:0.43327\n",
      "[36]\ttrain-mlogloss:0.28167\ttest-mlogloss:0.43155\n",
      "[37]\ttrain-mlogloss:0.27731\ttest-mlogloss:0.42955\n",
      "[38]\ttrain-mlogloss:0.27363\ttest-mlogloss:0.42829\n",
      "[39]\ttrain-mlogloss:0.26968\ttest-mlogloss:0.42701\n",
      "[40]\ttrain-mlogloss:0.26556\ttest-mlogloss:0.42588\n",
      "[41]\ttrain-mlogloss:0.26177\ttest-mlogloss:0.42472\n",
      "[42]\ttrain-mlogloss:0.25810\ttest-mlogloss:0.42399\n",
      "[43]\ttrain-mlogloss:0.25483\ttest-mlogloss:0.42378\n",
      "[44]\ttrain-mlogloss:0.25200\ttest-mlogloss:0.42349\n",
      "[45]\ttrain-mlogloss:0.24818\ttest-mlogloss:0.42246\n",
      "[46]\ttrain-mlogloss:0.24648\ttest-mlogloss:0.42215\n",
      "[47]\ttrain-mlogloss:0.24176\ttest-mlogloss:0.42093\n",
      "[48]\ttrain-mlogloss:0.24010\ttest-mlogloss:0.42059\n",
      "[49]\ttrain-mlogloss:0.23807\ttest-mlogloss:0.42030\n",
      "[50]\ttrain-mlogloss:0.23540\ttest-mlogloss:0.42003\n",
      "[51]\ttrain-mlogloss:0.23312\ttest-mlogloss:0.41968\n",
      "[52]\ttrain-mlogloss:0.23136\ttest-mlogloss:0.41941\n",
      "[53]\ttrain-mlogloss:0.22987\ttest-mlogloss:0.41905\n",
      "[54]\ttrain-mlogloss:0.22837\ttest-mlogloss:0.41891\n",
      "[55]\ttrain-mlogloss:0.22566\ttest-mlogloss:0.41852\n",
      "[56]\ttrain-mlogloss:0.22425\ttest-mlogloss:0.41818\n",
      "[57]\ttrain-mlogloss:0.22251\ttest-mlogloss:0.41796\n",
      "[58]\ttrain-mlogloss:0.22143\ttest-mlogloss:0.41762\n",
      "[59]\ttrain-mlogloss:0.21993\ttest-mlogloss:0.41725\n",
      "[60]\ttrain-mlogloss:0.21771\ttest-mlogloss:0.41715\n",
      "[61]\ttrain-mlogloss:0.21604\ttest-mlogloss:0.41696\n",
      "[62]\ttrain-mlogloss:0.21487\ttest-mlogloss:0.41657\n",
      "[63]\ttrain-mlogloss:0.21353\ttest-mlogloss:0.41645\n",
      "[64]\ttrain-mlogloss:0.21211\ttest-mlogloss:0.41621\n",
      "[65]\ttrain-mlogloss:0.21102\ttest-mlogloss:0.41604\n",
      "[66]\ttrain-mlogloss:0.21040\ttest-mlogloss:0.41604\n",
      "[67]\ttrain-mlogloss:0.20904\ttest-mlogloss:0.41582\n",
      "[68]\ttrain-mlogloss:0.20832\ttest-mlogloss:0.41579\n",
      "[69]\ttrain-mlogloss:0.20769\ttest-mlogloss:0.41579\n",
      "[70]\ttrain-mlogloss:0.20583\ttest-mlogloss:0.41545\n",
      "[71]\ttrain-mlogloss:0.20299\ttest-mlogloss:0.41513\n",
      "[72]\ttrain-mlogloss:0.20191\ttest-mlogloss:0.41489\n",
      "[73]\ttrain-mlogloss:0.20056\ttest-mlogloss:0.41485\n",
      "[74]\ttrain-mlogloss:0.19935\ttest-mlogloss:0.41461\n",
      "[75]\ttrain-mlogloss:0.19804\ttest-mlogloss:0.41454\n",
      "[76]\ttrain-mlogloss:0.19662\ttest-mlogloss:0.41457\n",
      "[77]\ttrain-mlogloss:0.19559\ttest-mlogloss:0.41448\n",
      "[78]\ttrain-mlogloss:0.19335\ttest-mlogloss:0.41431\n",
      "[79]\ttrain-mlogloss:0.19237\ttest-mlogloss:0.41430\n",
      "[80]\ttrain-mlogloss:0.19111\ttest-mlogloss:0.41432\n",
      "[81]\ttrain-mlogloss:0.19040\ttest-mlogloss:0.41436\n",
      "[82]\ttrain-mlogloss:0.18888\ttest-mlogloss:0.41445\n",
      "[83]\ttrain-mlogloss:0.18683\ttest-mlogloss:0.41431\n",
      "[84]\ttrain-mlogloss:0.18638\ttest-mlogloss:0.41416\n",
      "[85]\ttrain-mlogloss:0.18458\ttest-mlogloss:0.41368\n",
      "[86]\ttrain-mlogloss:0.18156\ttest-mlogloss:0.41346\n",
      "[87]\ttrain-mlogloss:0.18006\ttest-mlogloss:0.41326\n",
      "[88]\ttrain-mlogloss:0.17831\ttest-mlogloss:0.41305\n",
      "[89]\ttrain-mlogloss:0.17747\ttest-mlogloss:0.41292\n",
      "[90]\ttrain-mlogloss:0.17641\ttest-mlogloss:0.41289\n",
      "[91]\ttrain-mlogloss:0.17518\ttest-mlogloss:0.41274\n",
      "[92]\ttrain-mlogloss:0.17357\ttest-mlogloss:0.41278\n",
      "[93]\ttrain-mlogloss:0.17255\ttest-mlogloss:0.41293\n",
      "[94]\ttrain-mlogloss:0.17152\ttest-mlogloss:0.41302\n",
      "[95]\ttrain-mlogloss:0.17059\ttest-mlogloss:0.41306\n",
      "[96]\ttrain-mlogloss:0.16949\ttest-mlogloss:0.41285\n",
      "[97]\ttrain-mlogloss:0.16889\ttest-mlogloss:0.41279\n",
      "[98]\ttrain-mlogloss:0.16654\ttest-mlogloss:0.41287\n",
      "[99]\ttrain-mlogloss:0.16472\ttest-mlogloss:0.41248\n",
      "[100]\ttrain-mlogloss:0.16432\ttest-mlogloss:0.41244\n",
      "[101]\ttrain-mlogloss:0.16342\ttest-mlogloss:0.41253\n",
      "[102]\ttrain-mlogloss:0.16180\ttest-mlogloss:0.41254\n",
      "[103]\ttrain-mlogloss:0.15996\ttest-mlogloss:0.41260\n",
      "[104]\ttrain-mlogloss:0.15897\ttest-mlogloss:0.41271\n",
      "[105]\ttrain-mlogloss:0.15724\ttest-mlogloss:0.41265\n",
      "[106]\ttrain-mlogloss:0.15601\ttest-mlogloss:0.41264\n",
      "[107]\ttrain-mlogloss:0.15515\ttest-mlogloss:0.41264\n",
      "[108]\ttrain-mlogloss:0.15387\ttest-mlogloss:0.41255\n",
      "[109]\ttrain-mlogloss:0.15193\ttest-mlogloss:0.41250\n",
      "[110]\ttrain-mlogloss:0.15039\ttest-mlogloss:0.41235\n",
      "[111]\ttrain-mlogloss:0.14931\ttest-mlogloss:0.41242\n",
      "[112]\ttrain-mlogloss:0.14849\ttest-mlogloss:0.41264\n",
      "[113]\ttrain-mlogloss:0.14647\ttest-mlogloss:0.41266\n",
      "[114]\ttrain-mlogloss:0.14474\ttest-mlogloss:0.41243\n",
      "[115]\ttrain-mlogloss:0.14344\ttest-mlogloss:0.41241\n",
      "[116]\ttrain-mlogloss:0.14149\ttest-mlogloss:0.41254\n",
      "[117]\ttrain-mlogloss:0.14068\ttest-mlogloss:0.41248\n",
      "[118]\ttrain-mlogloss:0.13938\ttest-mlogloss:0.41245\n",
      "[119]\ttrain-mlogloss:0.13832\ttest-mlogloss:0.41243\n",
      "[120]\ttrain-mlogloss:0.13688\ttest-mlogloss:0.41251\n",
      "Accuracy of prediction on dataset: 0.8488237905015534\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "test_x_to_predict = xgb.DMatrix(test_x_A_reshape)\n",
    "\n",
    "# 设置参数\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3,\n",
    "    'eta': 0.1,\n",
    "    'reg_alpha': 0.01,\n",
    "    'reg_lambda': 0.01,\n",
    "    'max_depth': 8\n",
    "}\n",
    "\n",
    "# 训练模型\n",
    "bst = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    early_stopping_rounds=10,\n",
    "    num_boost_round=200,\n",
    "    evals=[(dtrain, 'train'), (dtest, 'test')] # 将训练数据和测试数据都作为验证集，可以实时监督训练情况，是否过拟合\n",
    ")\n",
    "\n",
    "# 预测结果\n",
    "result = bst.predict(\n",
    "    dtest\n",
    ")\n",
    "print('Accuracy of prediction on dataset:', accuracy_score(y_test, result))\n",
    "\n",
    "# 提交submit\n",
    "model = bst\n",
    "res = model.predict(test_x_to_predict)\n",
    "# res = np.array([np.argmax(l) for l in res])\n",
    "submit = pd.DataFrame({'id':range(len(res)), 'label':res}).astype('int32')\n",
    "submit.to_csv(f\"/Users/wzq/Desktop/game/DetectionOfSleep/submit/submit_example_A{time.strftime('%Y%m%d%H%M', time.localtime())}.csv\",index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不使用 k折"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不使用 k折\n",
    "import time\n",
    "\n",
    "\n",
    "callbacks = [log_evaluation(period=2), early_stopping(stopping_rounds=10)]\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "params = {'num_leaves': 491, # 叶节点数量\n",
    "        'n_estimators': 1000, # 设置训练轮数\n",
    "        'min_data_in_leaf': 106, # 每个叶子节点中的数据\n",
    "        'objective': 'multiclass', # 任务：多分类\n",
    "        'num_class': 3,\n",
    "        'max_depth': -1, # -1 ： 不限制深度\n",
    "        \"boosting_type\": \"gbdt\", # 'dart', 'goss', 'rf'\n",
    "        \"metric\": 'multi_logloss', # 衡量标准\n",
    "        \"verbosity\" : -1, # 不显示信息\n",
    "        'random_state': 66, # 随机种子\n",
    "        'learning_rate': 0.1,\n",
    "        # \"callbacks\": callbacks, # 添加回调函数\n",
    "        }\n",
    "model = lgb.LGBMClassifier(**params, nthread = 4, n_jobs = -1)\n",
    "model.fit(X_train, y_train,\n",
    "                eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "                eval_metric='multi_error',\n",
    "                callbacks=callbacks)\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"准确度\", score)\n",
    "\n",
    "y_pred = model.predict(test_x_A_reshape, num_iteration=model.best_iteration_)\n",
    "submit = pd.DataFrame({'id':range(len(y_pred)), 'label':y_pred})\n",
    "submit.to_csv(f\"/Users/wzq/Desktop/game/DetectionOfSleep/submit/submit_example_A{time.strftime('%Y%m%d%H%M', time.localtime())}.csv\",index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 0 折\n",
      "\n",
      "(30039, 360) (7510, 360) (30039,) (7510,)\n",
      "X_train_data shape : \t (30039, 360) X_val_data shape : \t (7510, 360)\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's multi_error: 0.185725\ttraining's multi_logloss: 0.514886\tvalid_1's multi_error: 0.287883\tvalid_1's multi_logloss: 0.716939\n",
      "[4]\ttraining's multi_error: 0.185725\ttraining's multi_logloss: 0.463382\tvalid_1's multi_error: 0.287883\tvalid_1's multi_logloss: 0.66729\n",
      "[6]\ttraining's multi_error: 0.181231\ttraining's multi_logloss: 0.425987\tvalid_1's multi_error: 0.285752\tvalid_1's multi_logloss: 0.633901\n",
      "[8]\ttraining's multi_error: 0.162755\ttraining's multi_logloss: 0.397617\tvalid_1's multi_error: 0.2751\tvalid_1's multi_logloss: 0.612377\n",
      "[10]\ttraining's multi_error: 0.145644\ttraining's multi_logloss: 0.373012\tvalid_1's multi_error: 0.260053\tvalid_1's multi_logloss: 0.594603\n",
      "[12]\ttraining's multi_error: 0.133893\ttraining's multi_logloss: 0.351751\tvalid_1's multi_error: 0.250866\tvalid_1's multi_logloss: 0.581755\n",
      "[14]\ttraining's multi_error: 0.123406\ttraining's multi_logloss: 0.332861\tvalid_1's multi_error: 0.244341\tvalid_1's multi_logloss: 0.571773\n",
      "[16]\ttraining's multi_error: 0.115583\ttraining's multi_logloss: 0.31516\tvalid_1's multi_error: 0.236218\tvalid_1's multi_logloss: 0.562588\n",
      "[18]\ttraining's multi_error: 0.108559\ttraining's multi_logloss: 0.299157\tvalid_1's multi_error: 0.231158\tvalid_1's multi_logloss: 0.555394\n",
      "[20]\ttraining's multi_error: 0.101568\ttraining's multi_logloss: 0.28396\tvalid_1's multi_error: 0.229028\tvalid_1's multi_logloss: 0.550794\n",
      "[22]\ttraining's multi_error: 0.0947435\ttraining's multi_logloss: 0.269472\tvalid_1's multi_error: 0.225699\tvalid_1's multi_logloss: 0.547148\n",
      "[24]\ttraining's multi_error: 0.088485\ttraining's multi_logloss: 0.255637\tvalid_1's multi_error: 0.223968\tvalid_1's multi_logloss: 0.544795\n",
      "[26]\ttraining's multi_error: 0.0810946\ttraining's multi_logloss: 0.242561\tvalid_1's multi_error: 0.223569\tvalid_1's multi_logloss: 0.54355\n",
      "[28]\ttraining's multi_error: 0.074836\ttraining's multi_logloss: 0.229809\tvalid_1's multi_error: 0.222636\tvalid_1's multi_logloss: 0.543727\n",
      "[30]\ttraining's multi_error: 0.0689437\ttraining's multi_logloss: 0.217813\tvalid_1's multi_error: 0.222903\tvalid_1's multi_logloss: 0.543921\n",
      "[32]\ttraining's multi_error: 0.0630847\ttraining's multi_logloss: 0.206409\tvalid_1's multi_error: 0.221305\tvalid_1's multi_logloss: 0.544385\n",
      "[34]\ttraining's multi_error: 0.0563934\ttraining's multi_logloss: 0.195341\tvalid_1's multi_error: 0.222104\tvalid_1's multi_logloss: 0.544395\n",
      "[36]\ttraining's multi_error: 0.050734\ttraining's multi_logloss: 0.185114\tvalid_1's multi_error: 0.220772\tvalid_1's multi_logloss: 0.545172\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's multi_error: 0.0786644\ttraining's multi_logloss: 0.236296\tvalid_1's multi_error: 0.22277\tvalid_1's multi_logloss: 0.543227\n",
      "准确度 0.7772303595206391\n",
      "第 1 折\n",
      "\n",
      "(30039, 360) (7510, 360) (30039,) (7510,)\n",
      "X_train_data shape : \t (30039, 360) X_val_data shape : \t (7510, 360)\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's multi_error: 0.201605\ttraining's multi_logloss: 0.542553\tvalid_1's multi_error: 0.224368\tvalid_1's multi_logloss: 0.621116\n",
      "[4]\ttraining's multi_error: 0.201605\ttraining's multi_logloss: 0.487372\tvalid_1's multi_error: 0.224368\tvalid_1's multi_logloss: 0.581015\n",
      "[6]\ttraining's multi_error: 0.193349\ttraining's multi_logloss: 0.447471\tvalid_1's multi_error: 0.21984\tvalid_1's multi_logloss: 0.555051\n",
      "[8]\ttraining's multi_error: 0.169813\ttraining's multi_logloss: 0.416003\tvalid_1's multi_error: 0.204394\tvalid_1's multi_logloss: 0.535813\n",
      "[10]\ttraining's multi_error: 0.151636\ttraining's multi_logloss: 0.390221\tvalid_1's multi_error: 0.194807\tvalid_1's multi_logloss: 0.523042\n",
      "[12]\ttraining's multi_error: 0.137821\ttraining's multi_logloss: 0.367912\tvalid_1's multi_error: 0.190679\tvalid_1's multi_logloss: 0.512335\n",
      "[14]\ttraining's multi_error: 0.128167\ttraining's multi_logloss: 0.348032\tvalid_1's multi_error: 0.185486\tvalid_1's multi_logloss: 0.502443\n",
      "[16]\ttraining's multi_error: 0.120377\ttraining's multi_logloss: 0.330289\tvalid_1's multi_error: 0.184288\tvalid_1's multi_logloss: 0.495218\n",
      "[18]\ttraining's multi_error: 0.113053\ttraining's multi_logloss: 0.313638\tvalid_1's multi_error: 0.180692\tvalid_1's multi_logloss: 0.489555\n",
      "[20]\ttraining's multi_error: 0.105996\ttraining's multi_logloss: 0.29783\tvalid_1's multi_error: 0.179893\tvalid_1's multi_logloss: 0.484986\n",
      "[22]\ttraining's multi_error: 0.0997037\ttraining's multi_logloss: 0.283158\tvalid_1's multi_error: 0.178828\tvalid_1's multi_logloss: 0.482719\n",
      "[24]\ttraining's multi_error: 0.0935118\ttraining's multi_logloss: 0.2688\tvalid_1's multi_error: 0.178562\tvalid_1's multi_logloss: 0.481182\n",
      "[26]\ttraining's multi_error: 0.0867539\ttraining's multi_logloss: 0.25536\tvalid_1's multi_error: 0.176565\tvalid_1's multi_logloss: 0.47944\n",
      "[28]\ttraining's multi_error: 0.0803289\ttraining's multi_logloss: 0.24229\tvalid_1's multi_error: 0.176964\tvalid_1's multi_logloss: 0.477127\n",
      "[30]\ttraining's multi_error: 0.0735044\ttraining's multi_logloss: 0.230214\tvalid_1's multi_error: 0.175499\tvalid_1's multi_logloss: 0.475493\n",
      "[32]\ttraining's multi_error: 0.0670462\ttraining's multi_logloss: 0.218418\tvalid_1's multi_error: 0.176698\tvalid_1's multi_logloss: 0.476006\n",
      "[34]\ttraining's multi_error: 0.061054\ttraining's multi_logloss: 0.207016\tvalid_1's multi_error: 0.176698\tvalid_1's multi_logloss: 0.476295\n",
      "[36]\ttraining's multi_error: 0.054862\ttraining's multi_logloss: 0.196391\tvalid_1's multi_error: 0.177364\tvalid_1's multi_logloss: 0.47599\n",
      "[38]\ttraining's multi_error: 0.047971\ttraining's multi_logloss: 0.185797\tvalid_1's multi_error: 0.176964\tvalid_1's multi_logloss: 0.478087\n",
      "[40]\ttraining's multi_error: 0.0425114\ttraining's multi_logloss: 0.175862\tvalid_1's multi_error: 0.17723\tvalid_1's multi_logloss: 0.478543\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's multi_error: 0.0735044\ttraining's multi_logloss: 0.230214\tvalid_1's multi_error: 0.175499\tvalid_1's multi_logloss: 0.475493\n",
      "准确度 0.8245006657789614\n",
      "第 2 折\n",
      "\n",
      "(30039, 360) (7510, 360) (30039,) (7510,)\n",
      "X_train_data shape : \t (30039, 360) X_val_data shape : \t (7510, 360)\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's multi_error: 0.189287\ttraining's multi_logloss: 0.522318\tvalid_1's multi_error: 0.273635\tvalid_1's multi_logloss: 0.689635\n",
      "[4]\ttraining's multi_error: 0.189287\ttraining's multi_logloss: 0.470042\tvalid_1's multi_error: 0.273635\tvalid_1's multi_logloss: 0.64124\n",
      "[6]\ttraining's multi_error: 0.181464\ttraining's multi_logloss: 0.431567\tvalid_1's multi_error: 0.269907\tvalid_1's multi_logloss: 0.607308\n",
      "[8]\ttraining's multi_error: 0.164553\ttraining's multi_logloss: 0.401399\tvalid_1's multi_error: 0.259121\tvalid_1's multi_logloss: 0.58288\n",
      "[10]\ttraining's multi_error: 0.147342\ttraining's multi_logloss: 0.376415\tvalid_1's multi_error: 0.246338\tvalid_1's multi_logloss: 0.567571\n",
      "[12]\ttraining's multi_error: 0.134758\ttraining's multi_logloss: 0.354966\tvalid_1's multi_error: 0.233688\tvalid_1's multi_logloss: 0.555311\n",
      "[14]\ttraining's multi_error: 0.124538\ttraining's multi_logloss: 0.335813\tvalid_1's multi_error: 0.229694\tvalid_1's multi_logloss: 0.546209\n",
      "[16]\ttraining's multi_error: 0.116515\ttraining's multi_logloss: 0.318785\tvalid_1's multi_error: 0.224634\tvalid_1's multi_logloss: 0.539728\n",
      "[18]\ttraining's multi_error: 0.108193\ttraining's multi_logloss: 0.301972\tvalid_1's multi_error: 0.219441\tvalid_1's multi_logloss: 0.533335\n",
      "[20]\ttraining's multi_error: 0.101102\ttraining's multi_logloss: 0.286631\tvalid_1's multi_error: 0.215846\tvalid_1's multi_logloss: 0.526459\n",
      "[22]\ttraining's multi_error: 0.0948434\ttraining's multi_logloss: 0.27197\tvalid_1's multi_error: 0.213981\tvalid_1's multi_logloss: 0.522369\n",
      "[24]\ttraining's multi_error: 0.0881188\ttraining's multi_logloss: 0.258174\tvalid_1's multi_error: 0.213582\tvalid_1's multi_logloss: 0.520144\n",
      "[26]\ttraining's multi_error: 0.0823263\ttraining's multi_logloss: 0.244837\tvalid_1's multi_error: 0.210919\tvalid_1's multi_logloss: 0.518578\n",
      "[28]\ttraining's multi_error: 0.0765005\ttraining's multi_logloss: 0.232241\tvalid_1's multi_error: 0.211585\tvalid_1's multi_logloss: 0.517269\n",
      "[30]\ttraining's multi_error: 0.0704085\ttraining's multi_logloss: 0.220108\tvalid_1's multi_error: 0.20972\tvalid_1's multi_logloss: 0.516423\n",
      "[32]\ttraining's multi_error: 0.0647159\ttraining's multi_logloss: 0.208915\tvalid_1's multi_error: 0.209321\tvalid_1's multi_logloss: 0.516396\n",
      "[34]\ttraining's multi_error: 0.0580246\ttraining's multi_logloss: 0.197611\tvalid_1's multi_error: 0.209987\tvalid_1's multi_logloss: 0.517426\n",
      "[36]\ttraining's multi_error: 0.0513998\ttraining's multi_logloss: 0.187119\tvalid_1's multi_error: 0.209987\tvalid_1's multi_logloss: 0.518266\n",
      "[38]\ttraining's multi_error: 0.0453411\ttraining's multi_logloss: 0.177349\tvalid_1's multi_error: 0.209055\tvalid_1's multi_logloss: 0.519127\n",
      "[40]\ttraining's multi_error: 0.0403475\ttraining's multi_logloss: 0.168051\tvalid_1's multi_error: 0.208655\tvalid_1's multi_logloss: 0.519373\n",
      "[42]\ttraining's multi_error: 0.03592\ttraining's multi_logloss: 0.159106\tvalid_1's multi_error: 0.208788\tvalid_1's multi_logloss: 0.519793\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's multi_error: 0.0647159\ttraining's multi_logloss: 0.208915\tvalid_1's multi_error: 0.209321\tvalid_1's multi_logloss: 0.516396\n",
      "准确度 0.7906790945406125\n",
      "第 3 折\n",
      "\n",
      "(30039, 360) (7510, 360) (30039,) (7510,)\n",
      "X_train_data shape : \t (30039, 360) X_val_data shape : \t (7510, 360)\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's multi_error: 0.205633\ttraining's multi_logloss: 0.554504\tvalid_1's multi_error: 0.208256\tvalid_1's multi_logloss: 0.575265\n",
      "[4]\ttraining's multi_error: 0.205633\ttraining's multi_logloss: 0.49905\tvalid_1's multi_error: 0.208256\tvalid_1's multi_logloss: 0.527591\n",
      "[6]\ttraining's multi_error: 0.198176\ttraining's multi_logloss: 0.458536\tvalid_1's multi_error: 0.205593\tvalid_1's multi_logloss: 0.496687\n",
      "[8]\ttraining's multi_error: 0.175172\ttraining's multi_logloss: 0.426784\tvalid_1's multi_error: 0.194274\tvalid_1's multi_logloss: 0.475732\n",
      "[10]\ttraining's multi_error: 0.158194\ttraining's multi_logloss: 0.400434\tvalid_1's multi_error: 0.18522\tvalid_1's multi_logloss: 0.460509\n",
      "[12]\ttraining's multi_error: 0.144512\ttraining's multi_logloss: 0.37837\tvalid_1's multi_error: 0.176831\tvalid_1's multi_logloss: 0.450389\n",
      "[14]\ttraining's multi_error: 0.134692\ttraining's multi_logloss: 0.358046\tvalid_1's multi_error: 0.172437\tvalid_1's multi_logloss: 0.442282\n",
      "[16]\ttraining's multi_error: 0.12587\ttraining's multi_logloss: 0.339614\tvalid_1's multi_error: 0.170573\tvalid_1's multi_logloss: 0.43753\n",
      "[18]\ttraining's multi_error: 0.118013\ttraining's multi_logloss: 0.322594\tvalid_1's multi_error: 0.169374\tvalid_1's multi_logloss: 0.43331\n",
      "[20]\ttraining's multi_error: 0.109824\ttraining's multi_logloss: 0.306468\tvalid_1's multi_error: 0.165379\tvalid_1's multi_logloss: 0.42975\n",
      "[22]\ttraining's multi_error: 0.101435\ttraining's multi_logloss: 0.290858\tvalid_1's multi_error: 0.166445\tvalid_1's multi_logloss: 0.426623\n",
      "[24]\ttraining's multi_error: 0.0951097\ttraining's multi_logloss: 0.276443\tvalid_1's multi_error: 0.164314\tvalid_1's multi_logloss: 0.424957\n",
      "[26]\ttraining's multi_error: 0.0862878\ttraining's multi_logloss: 0.262571\tvalid_1's multi_error: 0.164847\tvalid_1's multi_logloss: 0.425932\n",
      "[28]\ttraining's multi_error: 0.0801625\ttraining's multi_logloss: 0.249411\tvalid_1's multi_error: 0.162583\tvalid_1's multi_logloss: 0.426499\n",
      "[30]\ttraining's multi_error: 0.0740371\ttraining's multi_logloss: 0.236987\tvalid_1's multi_error: 0.162051\tvalid_1's multi_logloss: 0.428138\n",
      "[32]\ttraining's multi_error: 0.0674124\ttraining's multi_logloss: 0.225094\tvalid_1's multi_error: 0.160852\tvalid_1's multi_logloss: 0.430123\n",
      "[34]\ttraining's multi_error: 0.061287\ttraining's multi_logloss: 0.213771\tvalid_1's multi_error: 0.160719\tvalid_1's multi_logloss: 0.432042\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's multi_error: 0.0951097\ttraining's multi_logloss: 0.276443\tvalid_1's multi_error: 0.164314\tvalid_1's multi_logloss: 0.424957\n",
      "准确度 0.8356857523302264\n",
      "第 4 折\n",
      "\n",
      "(30040, 360) (7509, 360) (30040,) (7509,)\n",
      "X_train_data shape : \t (30040, 360) X_val_data shape : \t (7509, 360)\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's multi_error: 0.248535\ttraining's multi_logloss: 0.630185\tvalid_1's multi_error: 0.0366227\tvalid_1's multi_logloss: 0.341108\n",
      "[4]\ttraining's multi_error: 0.248535\ttraining's multi_logloss: 0.5682\tvalid_1's multi_error: 0.0366227\tvalid_1's multi_logloss: 0.340908\n",
      "[6]\ttraining's multi_error: 0.230659\ttraining's multi_logloss: 0.521292\tvalid_1's multi_error: 0.113331\tvalid_1's multi_logloss: 0.345732\n",
      "[8]\ttraining's multi_error: 0.200433\ttraining's multi_logloss: 0.484928\tvalid_1's multi_error: 0.149953\tvalid_1's multi_logloss: 0.35276\n",
      "[10]\ttraining's multi_error: 0.17986\ttraining's multi_logloss: 0.454647\tvalid_1's multi_error: 0.159409\tvalid_1's multi_logloss: 0.364072\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's multi_error: 0.248535\ttraining's multi_logloss: 0.672607\tvalid_1's multi_error: 0.0366227\tvalid_1's multi_logloss: 0.343568\n",
      "准确度 0.9633772805966174\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'loan_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[173], line 93\u001b[0m\n\u001b[1;32m     86\u001b[0m         best_model \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# 指定保存模型的文件夹\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# model_folder = '/Users/wzq/Desktop/game/DetectionOfSleep/model'\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# joblib.dump(best_model, model_folder + f'/{time.strftime('%Y%m%d%H%M%S', time.localtime())}.pkl')\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# 模型加载\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloan_model.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m最好的结果是第\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m折叠，分数为\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# lgb_model = lgb.train(params=params, # 超参数设置\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m#                     train_set=train_dataset, # 训练数据\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m#                     num_boost_round=100, # 循环的轮数\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# score = accuracy_score(y_val, y_val_pred)\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# print(f'Fold {k + 1} Accuracy of prediction on dataset:', score)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'loan_model.pkl'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "X = pd.DataFrame(train_data_x_reshape)\n",
    "y = pd.DataFrame(train_data_y)\n",
    "\n",
    "\n",
    "# 创建DataFrame保存特征重要性\n",
    "feature_importances = pd.DataFrame(index=None)\n",
    "feature_importances['features'] = X.columns\n",
    "\n",
    "\n",
    "# 5折交叉验证\n",
    "\n",
    "#将原始数据随机分为两组，一组做为训练集，一组做为验证集，利用训练集训练分类器，\n",
    "#然后利用验证集验证模型，记录最后的分类准确率为此分类器的性能指标。\n",
    "\n",
    "folds = KFold(n_splits=5)\n",
    "\n",
    "splits = folds.split(X, y) # 分割成5份，前4份是训练集索引，最后1份是验证集索引\n",
    "\n",
    "# next(iter(splits)) # 输出的是索引\n",
    "\n",
    "best_score = 0\n",
    "best_model = 0\n",
    "best_k = 0\n",
    "\n",
    "\n",
    "\n",
    "for k, (train_indices, val_indices) in enumerate(splits):\n",
    "    print(\"第 %d 折\\n\" % k)\n",
    "    \n",
    "    # iloc：根据标签的所在位置，从0开始计数，先选取行再选取列\n",
    "    X_train_data, X_val_data = X.iloc[train_indices], X.iloc[val_indices] # 训练集， 验证集\n",
    "    y_train, y_val = y.iloc[train_indices], y.iloc[val_indices] # 训练标签，验证标签\n",
    "    y_train = y_train.squeeze()\n",
    "    y_val = y_val.squeeze()\n",
    "    print(X_train_data.shape, X_val_data.shape,  y_train.shape, y_val.shape)\n",
    "\n",
    "    print(\"X_train_data shape : \\t\", X_train_data.shape, \"X_val_data shape : \\t\", X_val_data.shape)\n",
    "    \n",
    "    #这里调用了 lightGBM 算法 ，第一个是传入数据，第二个是数据的标签\n",
    "\n",
    "    # params 超参数设置  https://blog.csdn.net/VariableX/article/details/107256149\n",
    "    callbacks = [log_evaluation(period=2), early_stopping(stopping_rounds=10)]\n",
    "\n",
    "    params = {'num_leaves': 491, # 叶节点数量\n",
    "            'n_estimators': 1000, # 设置训练轮数\n",
    "            'min_data_in_leaf': 106, # 每个叶子节点中的数据\n",
    "            'objective': 'multiclass', # 任务：多分类\n",
    "            'num_class': 3,\n",
    "            'max_depth': -1, # -1 ： 不限制深度\n",
    "            \"boosting_type\": \"gbdt\", # 'dart', 'goss', 'rf'\n",
    "            \"metric\": 'multi_logloss', # 衡量标准\n",
    "            \"verbosity\" : -1, # 不显示信息\n",
    "            'random_state': 66, # 随机种子\n",
    "            'learning_rate': 0.1,\n",
    "            # \"callbacks\": callbacks, # 添加回调函数\n",
    "            }\n",
    "\n",
    "    # train_dataset = lgb.Dataset(X_train_data, label=y_train) # 训练集\n",
    "    # val_dataset = lgb.Dataset(X_val_data, label=y_val) # 验证集\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**params, nthread = 4, n_jobs = -1)\n",
    "    model.fit(X_train_data, y_train,\n",
    "                    eval_set=[(X_train_data, y_train), (X_val_data, y_val)],\n",
    "                    eval_metric='multi_error',\n",
    "                    callbacks=callbacks)\n",
    "    y_pred = model.predict(X_val_data, num_iteration=model.best_iteration_)\n",
    "    score = accuracy_score(y_val, y_pred)\n",
    "    print(\"准确度\", score)\n",
    "\n",
    "\n",
    "    # 指定保存模型的文件夹\n",
    "    model_folder = '/Users/wzq/Desktop/game/DetectionOfSleep/model'\n",
    "\n",
    "    # 如果文件夹不存在，则创建文件夹\n",
    "    if not os.path.exists(model_folder):\n",
    "        os.makedirs(model_folder)\n",
    "    # 判断是否是最优模型\n",
    "    if score > best_score:\n",
    "        best_k = k\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "\n",
    "\n",
    "# 指定保存模型的文件夹\n",
    "# model_folder = '/Users/wzq/Desktop/game/DetectionOfSleep/model'\n",
    "# joblib.dump(best_model, model_folder + f'/{time.strftime('%Y%m%d%H%M%S', time.localtime())}.pkl')\n",
    "# 模型加载\n",
    "# model = joblib.load('loan_model.pkl')\n",
    "print(f\"最好的结果是第{best_k}折叠，分数为{best_score}\")\n",
    "\n",
    "\n",
    "    # lgb_model = lgb.train(params=params, # 超参数设置\n",
    "    #                     train_set=train_dataset, # 训练数据\n",
    "    #                     num_boost_round=100, # 循环的轮数\n",
    "    #                     valid_sets=val_dataset, # 验证数据\n",
    "    #                     valid_names='validation',) # 验证集名称\n",
    "    \n",
    "    # 保存特征重要性\n",
    "    # feature_importances[f'fold_{k+1}'] = lgb_model.feature_importance()\n",
    "    #print(\"看一看有啥东西{}\".format())\n",
    "    # 对验证集进行预测\n",
    "    # y_val_pred = lgb_model.predict(X_val_data)\n",
    "    # y_val_pred = np.array([np.argmax(l) for l in y_val_pred])\n",
    "    # print(y_val.squeeze(1).shape, y_val_pred.shape)\n",
    "    # # 计算roc_auc  # 训练数据label类别分布不均衡 (0   29808) (2     4520) (1     3221) 利用ovo\n",
    "    # score = accuracy_score(y_val, y_val_pred)\n",
    "    # print(f'Fold {k + 1} Accuracy of prediction on dataset:', score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最好的结果是第4折叠，分数为0.9633772805966174\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(f\"最好的结果是第{best_k}折叠，分数为{best_score}\")\n",
    "res = best_model.predict(test_x_A_reshape)\n",
    "for i in res:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提交submit\n",
    "mode = best_model\n",
    "res = model.predict(test_x_A_reshape)\n",
    "# res = np.array([np.argmax(l) for l in res])\n",
    "submit = pd.DataFrame({'id':range(len(res)), 'label':res})\n",
    "# submit.to_csv(f\"/Users/wzq/Desktop/game/DetectionOfSleep/submit/submit_example_A{time.strftime('%Y%m%d%H%M', time.localtime())}.csv\",index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
